{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-08T12:04:32.266038Z",
     "iopub.status.busy": "2025-09-08T12:04:32.265754Z",
     "iopub.status.idle": "2025-09-08T12:04:32.764735Z",
     "shell.execute_reply": "2025-09-08T12:04:32.764169Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\r\n",
      "Requirement already satisfied: scikit-learn in /Users/valentinaovallevelandia/Library/Python/3.9/lib/python/site-packages (1.6.1)\r\n",
      "Requirement already satisfied: numpy>=1.19.5 in /Users/valentinaovallevelandia/Library/Python/3.9/lib/python/site-packages (from scikit-learn) (2.0.2)\r\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Users/valentinaovallevelandia/Library/Python/3.9/lib/python/site-packages (from scikit-learn) (1.13.1)\r\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/valentinaovallevelandia/Library/Python/3.9/lib/python/site-packages (from scikit-learn) (1.5.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/valentinaovallevelandia/Library/Python/3.9/lib/python/site-packages (from scikit-learn) (3.6.0)\r\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-08T12:04:32.766903Z",
     "iopub.status.busy": "2025-09-08T12:04:32.766708Z",
     "iopub.status.idle": "2025-09-08T12:04:33.621894Z",
     "shell.execute_reply": "2025-09-08T12:04:33.621585Z"
    },
    "id": "nz4Kx7ryJCRP"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score, balanced_accuracy_score, classification_report\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier\n",
    "from IPython.display import display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-08T12:04:33.623129Z",
     "iopub.status.busy": "2025-09-08T12:04:33.623027Z",
     "iopub.status.idle": "2025-09-08T12:04:33.625878Z",
     "shell.execute_reply": "2025-09-08T12:04:33.625652Z"
    },
    "id": "LGLLvxKHLoha"
   },
   "outputs": [],
   "source": [
    "RANDOM_STATE   = 42\n",
    "PREDICT_MONTH  = pd.Period('2023-07', 'M')   # month to predict\n",
    "TRAIN_END   = pd.Period('2023-06', 'M')   # last month with labels for training\n",
    "SHIFT_MACRO_BY = 1                           # shift macro features by +1M to avoid release leakage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-08T12:04:33.626828Z",
     "iopub.status.busy": "2025-09-08T12:04:33.626759Z",
     "iopub.status.idle": "2025-09-08T12:04:33.661285Z",
     "shell.execute_reply": "2025-09-08T12:04:33.660986Z"
    },
    "id": "IgONDoPbX__X"
   },
   "outputs": [],
   "source": [
    "stock = pd.read_csv(\"stock_data.csv\")\n",
    "index  = pd.read_csv(\"monashIndex.csv\")\n",
    "company  = pd.read_csv(\"company_info.csv\")\n",
    "vix    = pd.read_csv(\"vix_index.csv\")\n",
    "us10yt     = pd.read_csv(\"us_10_year_treasury.csv\")\n",
    "us5yt      = pd.read_csv(\"us_5_year_treasury.csv\")\n",
    "infl     = pd.read_csv(\"fed_inflation_rate.csv\")\n",
    "fedfunds = pd.read_csv(\"fed_funds_rate.csv\")\n",
    "unemp     = pd.read_csv(\"fed_unemployment_rate.csv\")\n",
    "train_tgt= pd.read_csv(\"training_targets.csv\").astype({\"stock_id\":\"str\"})\n",
    "test_tgt  = pd.read_csv(\"testing_targets.csv\").astype({\"stock_id\":\"str\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-09-08T12:04:33.662423Z",
     "iopub.status.busy": "2025-09-08T12:04:33.662346Z",
     "iopub.status.idle": "2025-09-08T12:04:33.673141Z",
     "shell.execute_reply": "2025-09-08T12:04:33.672943Z"
    },
    "id": "Rk10XhgV9aJg",
    "outputId": "8d2c22fb-4c27-480a-ea2e-7e3c051ec6bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "macro_feat shape: (42, 14)\n"
     ]
    }
   ],
   "source": [
    "# Sort by time for rolling/lag operations\n",
    "def lag_and_roll(df, col, l1=True, mean3=True, time_col=\"month_id\"):\n",
    "    df = df.sort_values(time_col).copy()\n",
    "    out = pd.DataFrame({time_col: df[time_col]})\n",
    "    if l1:\n",
    "        out[f\"{col}_lag1\"] = df[col].shift(1)\n",
    "    if mean3:\n",
    "        out[f\"{col}_mean_3m\"] = df[col].shift(1).rolling(3, min_periods=1).mean()\n",
    "    return out\n",
    "\n",
    "vix_feat = lag_and_roll(vix, \"vix\")  # vix_lag1, vix_mean_3m\n",
    "\n",
    "yields = (us10yt.merge(us5yt, on=\"month_id\", how=\"outer\")\n",
    "            .sort_values(\"month_id\"))\n",
    "yields_feat = yields[[\"month_id\"]].copy()\n",
    "yields_feat[\"y10_lag1\"] = yields[\"10y_treasury\"].shift(1)\n",
    "yields_feat[\"y5_lag1\"]  = yields[\"5y_treasury\"].shift(1)\n",
    "yields_feat[\"term_slope_lag1\"] = yields_feat[\"y10_lag1\"] - yields_feat[\"y5_lag1\"]\n",
    "\n",
    "fed = fedfunds.sort_values(\"month_id\")\n",
    "fed_feat = fed[[\"month_id\"]].copy()\n",
    "fed_feat[\"fed_rate_lag1\"]   = fed[\"fed_rate\"].shift(1)\n",
    "# 3-month change (t-1 vs t-4)\n",
    "fed_feat[\"fed_rate_chg_3m\"] = fed[\"fed_rate\"].shift(1) - fed[\"fed_rate\"].shift(4)\n",
    "\n",
    "cpi_feat = lag_and_roll(infl, \"inflation_rate\")  # inflation_rate_lag1, inflation_rate_mean_3m\n",
    "cpi_feat = cpi_feat.rename(columns={\n",
    "    \"inflation_rate_lag1\": \"inflation_rate_lag1\",\n",
    "    \"inflation_rate_mean_3m\": \"inflation_3m_mean\"\n",
    "})\n",
    "\n",
    "unemp = unemp.sort_values(\"month_id\")\n",
    "unemp_feat = unemp[[\"month_id\"]].copy()\n",
    "unemp_feat[\"unemployment_rate_lag1\"] = unemp[\"unemployment_rate\"].shift(1)\n",
    "\n",
    "# Index context\n",
    "idx = index.sort_values(\"month_id\")\n",
    "idx_feat = idx[[\"month_id\"]].copy()\n",
    "idx_feat[\"index_return_lag1\"]     = idx[\"index_return\"].shift(1)\n",
    "idx_feat[\"index_return_mean_3m\"]  = idx[\"index_return\"].shift(1).rolling(3, min_periods=1).mean()\n",
    "# trailing 3m drawdown using index_value known by t-1\n",
    "roll_max = idx[\"index_value\"].shift(1).rolling(3, min_periods=1).max()\n",
    "idx_feat[\"index_value_dd_3m\"] = (idx[\"index_value\"].shift(1) - roll_max) / roll_max\n",
    "\n",
    "# Combine all macro + index features\n",
    "macro_feat = (\n",
    "    vix_feat.merge(yields_feat, on=\"month_id\", how=\"outer\")\n",
    "            .merge(fed_feat, on=\"month_id\", how=\"outer\")\n",
    "            .merge(cpi_feat, on=\"month_id\", how=\"outer\")\n",
    "            .merge(unemp_feat, on=\"month_id\", how=\"outer\")\n",
    "            .merge(idx_feat, on=\"month_id\", how=\"outer\")\n",
    "            .sort_values(\"month_id\")\n",
    ")\n",
    "\n",
    "print(\"macro_feat shape:\", macro_feat.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-09-08T12:04:33.674114Z",
     "iopub.status.busy": "2025-09-08T12:04:33.674041Z",
     "iopub.status.idle": "2025-09-08T12:04:33.684801Z",
     "shell.execute_reply": "2025-09-08T12:04:33.684571Z"
    },
    "id": "ezySJz3X-jM7",
    "outputId": "c5f71601-b106-4e7b-ff5a-69464d65ee66"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stock_feat shape: (24867, 18)\n"
     ]
    }
   ],
   "source": [
    "stock = stock.sort_values([\"stock_id\", \"month_id\"]).copy()\n",
    "\n",
    "# Pick the columns to lag (all time-varying)\n",
    "to_lag = [\n",
    "    \"month_start_open_usd\",\"month_end_close_usd\",\n",
    "    \"month_high_usd\",\"month_low_usd\",\n",
    "    \"monthly_volume\",\"intramonth_return\",\"intramonth_volatility\",\n",
    "    \"return_1m\",\"return_3m\",\"return_6m\",\n",
    "    \"volatility_3m\",\"volatility_6m\",\n",
    "    \"trading_days\",\"avg_volume_3m\",\"volume_ratio\",\"price_range_ratio\"\n",
    "]\n",
    "\n",
    "missing_cols = [c for c in to_lag if c not in stock.columns]\n",
    "if missing_cols:\n",
    "    raise ValueError(f\"Missing columns in stock_data.csv: {missing_cols}\")\n",
    "\n",
    "# Create *_lag1 versions aligned to the current month_id\n",
    "lagged = stock.groupby(\"stock_id\")[to_lag].shift(1)\n",
    "lagged.columns = [f\"{c}_lag1\" for c in to_lag]\n",
    "\n",
    "stock_feat = pd.concat([stock[[\"stock_id\",\"month_id\"]], lagged], axis=1)\n",
    "\n",
    "# Drop the first available month per stock (no lag yet)\n",
    "stock_feat = stock_feat.dropna(subset=[col for col in stock_feat.columns if col.endswith(\"_lag1\")])\n",
    "\n",
    "print(\"stock_feat shape:\", stock_feat.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 210
    },
    "execution": {
     "iopub.execute_input": "2025-09-08T12:04:33.685777Z",
     "iopub.status.busy": "2025-09-08T12:04:33.685700Z",
     "iopub.status.idle": "2025-09-08T12:04:33.706358Z",
     "shell.execute_reply": "2025-09-08T12:04:33.706130Z"
    },
    "id": "4fiTe8IL-mE9",
    "outputId": "bdff92c5-a855-4385-b521-60dbe9f57b30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features_panel shape: (24867, 70)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_id</th>\n",
       "      <th>month_id</th>\n",
       "      <th>month_start_open_usd_lag1</th>\n",
       "      <th>month_end_close_usd_lag1</th>\n",
       "      <th>month_high_usd_lag1</th>\n",
       "      <th>month_low_usd_lag1</th>\n",
       "      <th>monthly_volume_lag1</th>\n",
       "      <th>intramonth_return_lag1</th>\n",
       "      <th>intramonth_volatility_lag1</th>\n",
       "      <th>return_1m_lag1</th>\n",
       "      <th>...</th>\n",
       "      <th>revenue_tier=Tier_3</th>\n",
       "      <th>profitability_profile=High_Margin</th>\n",
       "      <th>profitability_profile=Low_Margin</th>\n",
       "      <th>profitability_profile=Standard</th>\n",
       "      <th>asset_intensity=Asset_Light</th>\n",
       "      <th>asset_intensity=Capital_Intensive</th>\n",
       "      <th>asset_intensity=Moderate</th>\n",
       "      <th>financial_strength=Developing</th>\n",
       "      <th>financial_strength=Stable</th>\n",
       "      <th>financial_strength=Strong</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US001</td>\n",
       "      <td>2020_02</td>\n",
       "      <td>120.192</td>\n",
       "      <td>107.326</td>\n",
       "      <td>123.486</td>\n",
       "      <td>107.035</td>\n",
       "      <td>84539259.0</td>\n",
       "      <td>-0.107045</td>\n",
       "      <td>0.253304</td>\n",
       "      <td>-0.100669</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>US001</td>\n",
       "      <td>2020_03</td>\n",
       "      <td>108.252</td>\n",
       "      <td>101.868</td>\n",
       "      <td>111.641</td>\n",
       "      <td>99.636</td>\n",
       "      <td>91313882.0</td>\n",
       "      <td>-0.058974</td>\n",
       "      <td>0.259208</td>\n",
       "      <td>-0.050854</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US001</td>\n",
       "      <td>2020_04</td>\n",
       "      <td>103.301</td>\n",
       "      <td>93.178</td>\n",
       "      <td>105.622</td>\n",
       "      <td>77.841</td>\n",
       "      <td>177930833.0</td>\n",
       "      <td>-0.097995</td>\n",
       "      <td>0.892709</td>\n",
       "      <td>-0.085299</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  stock_id month_id  month_start_open_usd_lag1  month_end_close_usd_lag1  \\\n",
       "0    US001  2020_02                    120.192                   107.326   \n",
       "1    US001  2020_03                    108.252                   101.868   \n",
       "2    US001  2020_04                    103.301                    93.178   \n",
       "\n",
       "   month_high_usd_lag1  month_low_usd_lag1  monthly_volume_lag1  \\\n",
       "0              123.486             107.035           84539259.0   \n",
       "1              111.641              99.636           91313882.0   \n",
       "2              105.622              77.841          177930833.0   \n",
       "\n",
       "   intramonth_return_lag1  intramonth_volatility_lag1  return_1m_lag1  ...  \\\n",
       "0               -0.107045                    0.253304       -0.100669  ...   \n",
       "1               -0.058974                    0.259208       -0.050854  ...   \n",
       "2               -0.097995                    0.892709       -0.085299  ...   \n",
       "\n",
       "   revenue_tier=Tier_3  profitability_profile=High_Margin  \\\n",
       "0                False                              False   \n",
       "1                False                              False   \n",
       "2                False                              False   \n",
       "\n",
       "   profitability_profile=Low_Margin  profitability_profile=Standard  \\\n",
       "0                             False                            True   \n",
       "1                             False                            True   \n",
       "2                             False                            True   \n",
       "\n",
       "   asset_intensity=Asset_Light  asset_intensity=Capital_Intensive  \\\n",
       "0                        False                              False   \n",
       "1                        False                              False   \n",
       "2                        False                              False   \n",
       "\n",
       "   asset_intensity=Moderate  financial_strength=Developing  \\\n",
       "0                      True                          False   \n",
       "1                      True                          False   \n",
       "2                      True                          False   \n",
       "\n",
       "   financial_strength=Stable  financial_strength=Strong  \n",
       "0                       True                      False  \n",
       "1                       True                      False  \n",
       "2                       True                      False  \n",
       "\n",
       "[3 rows x 70 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure company_ohe exists (one-hot of company_info)\n",
    "if 'company_ohe' not in globals():\n",
    "    cat_cols = ['sector','business_model','geographic_focus','business_maturity','competitive_position',\n",
    "                'market_cap_category','revenue_tier','profitability_profile','asset_intensity','financial_strength']\n",
    "    comp = company[['stock_id'] + cat_cols].copy()\n",
    "    company_ohe = pd.get_dummies(comp, columns=cat_cols, prefix=cat_cols, prefix_sep='=')\n",
    "\n",
    "features_panel = (\n",
    "    stock_feat\n",
    "    .merge(macro_feat, on=\"month_id\", how=\"left\")\n",
    "    .merge(company_ohe, on=\"stock_id\", how=\"left\")\n",
    "    .sort_values([\"stock_id\",\"month_id\"])\n",
    ")\n",
    "\n",
    "print(\"features_panel shape:\", features_panel.shape)\n",
    "features_panel.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-08T12:04:33.707283Z",
     "iopub.status.busy": "2025-09-08T12:04:33.707211Z",
     "iopub.status.idle": "2025-09-08T12:04:33.714833Z",
     "shell.execute_reply": "2025-09-08T12:04:33.714643Z"
    },
    "id": "MBuFfgT8f9pC"
   },
   "outputs": [],
   "source": [
    "macro = (\n",
    "    vix[[\"month_id\", \"vix\"]]\n",
    "    .merge(us10yt[[\"month_id\", \"10y_treasury\"]], on=\"month_id\", how=\"outer\")\n",
    "    .merge(us5yt[[\"month_id\", \"5y_treasury\"]], on=\"month_id\", how=\"outer\")\n",
    "    .merge(infl[[\"month_id\", \"inflation_rate\"]], on=\"month_id\", how=\"outer\")\n",
    "    .merge(fedfunds[[\"month_id\", \"fed_rate\"]], on=\"month_id\", how=\"outer\")\n",
    "    .merge(unemp[[\"month_id\", \"unemployment_rate\"]], on=\"month_id\", how=\"outer\")\n",
    "    .merge(index[[\"month_id\", \"index_return\", \"index_value\"]], on=\"month_id\", how=\"outer\")\n",
    "    .sort_values(\"month_id\")\n",
    ")\n",
    "\n",
    "# engineered macro fields\n",
    "macro[\"TERM_SPREAD\"] = macro[\"10y_treasury\"] - macro[\"5y_treasury\"]\n",
    "macro[\"REAL_RATE_PROXY\"] = macro[\"10y_treasury\"] - macro[\"inflation_rate\"]\n",
    "for col in [\"vix\", \"10y_treasury\", \"5y_treasury\", \"inflation_rate\", \"fed_rate\", \"unemployment_rate\"]:\n",
    "    macro[f\"{col}_CHG_1M\"] = macro[col].diff()\n",
    "\n",
    "# lag ALL macro features by 1 month to avoid leak\n",
    "macro_lag = macro.copy()\n",
    "macro_cols = [c for c in macro.columns if c != \"month_id\"]\n",
    "macro_lag[macro_cols] = macro_lag[macro_cols].shift(1)\n",
    "macro_lag = macro_lag.rename(columns={c: f\"{c}_lag1\" for c in macro_cols})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-08T12:04:33.715724Z",
     "iopub.status.busy": "2025-09-08T12:04:33.715661Z",
     "iopub.status.idle": "2025-09-08T12:04:33.719095Z",
     "shell.execute_reply": "2025-09-08T12:04:33.718829Z"
    },
    "id": "wVPVhzuS2d6I"
   },
   "outputs": [],
   "source": [
    "stock = stock.sort_values([\"stock_id\", \"month_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-08T12:04:33.720017Z",
     "iopub.status.busy": "2025-09-08T12:04:33.719955Z",
     "iopub.status.idle": "2025-09-08T12:04:33.747388Z",
     "shell.execute_reply": "2025-09-08T12:04:33.747096Z"
    },
    "id": "wxAuTXrW19k2"
   },
   "outputs": [],
   "source": [
    "to_lag = [\n",
    "    \"return_1m\",\"return_3m\",\"return_6m\",\n",
    "    \"intramonth_volatility\",\"volatility_3m\",\"volatility_6m\",\n",
    "    \"volume_ratio\",\"avg_volume_3m\",\"monthly_volume\",\n",
    "    \"price_range_ratio\",\"trading_days\"\n",
    "]\n",
    "to_lag = [c for c in to_lag if c in stock.columns]\n",
    "\n",
    "for c in to_lag:\n",
    "    stock[f\"{c}_lag1\"] = stock.groupby(\"stock_id\")[c].shift(1)\n",
    "\n",
    "lag_feats = sorted([f\"{c}_lag1\" for c in to_lag if f\"{c}_lag1\" in stock.columns])\n",
    "\n",
    "# Build panel of features only (lagged stock + lagged macro) + company info\n",
    "panel = stock[[\"stock_id\",\"month_id\"] + lag_feats].merge(macro_lag, on=\"month_id\", how=\"left\")\n",
    "panel = panel.merge(company, on=\"stock_id\", how=\"left\")\n",
    "\n",
    "# Add training labels by merge (do NOT compute from prices here)\n",
    "panel = panel.merge(\n",
    "    train_tgt[[\"stock_id\",\"month_id\",\"outperform_binary\"]],\n",
    "    on=[\"stock_id\",\"month_id\"], how=\"left\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-09-08T12:04:33.748388Z",
     "iopub.status.busy": "2025-09-08T12:04:33.748321Z",
     "iopub.status.idle": "2025-09-08T12:04:33.758815Z",
     "shell.execute_reply": "2025-09-08T12:04:33.758620Z"
    },
    "id": "kmuq1iGiugE9",
    "outputId": "a958ac6f-b4e3-43a8-db58-4a0281c8b65b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8g/2nwmz93j45s_r3g3lzds5fmr0000gn/T/ipykernel_19289/1664793713.py:5: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[col] = pd.to_datetime(df[col].astype(str), errors=\"coerce\").dt.to_period(\"M\")\n",
      "/var/folders/8g/2nwmz93j45s_r3g3lzds5fmr0000gn/T/ipykernel_19289/1664793713.py:5: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[col] = pd.to_datetime(df[col].astype(str), errors=\"coerce\").dt.to_period(\"M\")\n",
      "/var/folders/8g/2nwmz93j45s_r3g3lzds5fmr0000gn/T/ipykernel_19289/1664793713.py:5: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[col] = pd.to_datetime(df[col].astype(str), errors=\"coerce\").dt.to_period(\"M\")\n",
      "/var/folders/8g/2nwmz93j45s_r3g3lzds5fmr0000gn/T/ipykernel_19289/1664793713.py:5: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[col] = pd.to_datetime(df[col].astype(str), errors=\"coerce\").dt.to_period(\"M\")\n"
     ]
    }
   ],
   "source": [
    "# ---- HARD CAST month_id to Period[M] everywhere (fix for '<=' TypeError) ----\n",
    "def force_period_m(df, col=\"month_id\"):\n",
    "    if col in df.columns:\n",
    "        # Use .dt.to_period(\"M\") for correct conversion\n",
    "        df[col] = pd.to_datetime(df[col].astype(str), errors=\"coerce\").dt.to_period(\"M\")\n",
    "    return df\n",
    "\n",
    "stock     = force_period_m(stock)\n",
    "macro_lag = force_period_m(macro_lag)\n",
    "train_tgt = force_period_m(train_tgt)\n",
    "test_tgt  = force_period_m(test_tgt)\n",
    "panel     = force_period_m(panel)\n",
    "\n",
    "# (optional sanity) - Removed print statement causing NameError\n",
    "# print(\"DTypes:\",\n",
    "#       \"panel.month_id ->\", panel[\"month_id\"].dtype,\n",
    "#       \"| tjm1 type ->\", type(tjm1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-09-08T12:04:33.759740Z",
     "iopub.status.busy": "2025-09-08T12:04:33.759676Z",
     "iopub.status.idle": "2025-09-08T12:04:35.635080Z",
     "shell.execute_reply": "2025-09-08T12:04:35.634805Z"
    },
    "id": "ox-Eq7K1uSr6",
    "outputId": "d4d8dc0c-c7f3-40e2-9719-3c8315d9dbb5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaT NaT\n",
      "Unique test months: ['NaT']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train/test shapes: (1069738, 37) (25618, 37)\n",
      "Numeric columns: ['avg_volume_3m_lag1', 'intramonth_volatility_lag1', 'monthly_volume_lag1', 'price_range_ratio_lag1', 'return_1m_lag1', 'return_3m_lag1', 'return_6m_lag1', 'trading_days_lag1', 'volatility_3m_lag1', 'volatility_6m_lag1', 'volume_ratio_lag1', 'vix_lag1', '10y_treasury_lag1', '5y_treasury_lag1', 'inflation_rate_lag1', 'fed_rate_lag1', 'unemployment_rate_lag1', 'index_return_lag1', 'index_value_lag1', 'TERM_SPREAD_lag1', 'REAL_RATE_PROXY_lag1', 'vix_CHG_1M_lag1', '10y_treasury_CHG_1M_lag1', '5y_treasury_CHG_1M_lag1', 'inflation_rate_CHG_1M_lag1', 'fed_rate_CHG_1M_lag1', 'unemployment_rate_CHG_1M_lag1']\n",
      "Categorical columns: ['sector', 'business_model', 'geographic_focus', 'business_maturity', 'competitive_position', 'market_cap_category', 'revenue_tier', 'profitability_profile', 'asset_intensity', 'financial_strength']\n"
     ]
    }
   ],
   "source": [
    "train_df = (train_tgt\n",
    "            .merge(panel, on=[\"stock_id\",\"month_id\"], how=\"inner\")\n",
    "            .sort_values([\"stock_id\",\"month_id\"]))\n",
    "test_df  = (test_tgt\n",
    "            .merge(panel, on=[\"stock_id\",\"month_id\"], how=\"left\")\n",
    "            .sort_values([\"stock_id\",\"month_id\"]))\n",
    "\n",
    "print(train_df[\"month_id\"].min(), train_df[\"month_id\"].max())\n",
    "print(\"Unique test months:\", sorted(test_df[\"month_id\"].unique().astype(str)))\n",
    "\n",
    "# Feature columns = everything except identifiers & labels\n",
    "# Adjusted to exclude the merged target columns\n",
    "drop_cols = [\"stock_id\",\"month_id\",\"outperform_binary_x\",\"outperform_binary_y\",\"test_outperform\",\"excess_return\"]\n",
    "feat_cols = [c for c in train_df.columns if c not in drop_cols]\n",
    "\n",
    "X_train = train_df[feat_cols].replace([np.inf, -np.inf], np.nan)\n",
    "# Use the correctly named target column from the merge for y_train\n",
    "y_train = train_df[\"outperform_binary_x\"].astype(int)\n",
    "\n",
    "X_test  = test_df[feat_cols].replace([np.inf, -np.inf], np.nan)\n",
    "# Removed y_test creation as y_test_jul is used for evaluation\n",
    "\n",
    "\n",
    "# Consistent NA imputation from TRAIN medians\n",
    "train_medians = X_train.median(numeric_only=True)\n",
    "X_train = X_train.fillna(train_medians)\n",
    "X_test  = X_test.fillna(train_medians)\n",
    "\n",
    "# Define numeric and categorical columns based on X_train\n",
    "numeric_cols = X_train.select_dtypes(include=np.number).columns.tolist()\n",
    "categorical_cols = X_train.select_dtypes(include='object').columns.tolist()\n",
    "\n",
    "\n",
    "print(\"X_train/test shapes:\", X_train.shape, X_test.shape)\n",
    "print(\"Numeric columns:\", numeric_cols)\n",
    "print(\"Categorical columns:\", categorical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-09-08T12:04:35.636292Z",
     "iopub.status.busy": "2025-09-08T12:04:35.636203Z",
     "iopub.status.idle": "2025-09-08T12:04:35.639690Z",
     "shell.execute_reply": "2025-09-08T12:04:35.639463Z"
    },
    "id": "yvU-_JXP7Uuy",
    "outputId": "6c8a2dff-6254-4652-db75-baec24bba282"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Panel month range: NaT → NaT\n",
      "Counts by month (tail):\n",
      "Series([], Freq: M, Name: count, dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "print(\"Panel month range:\", panel[\"month_id\"].min(), \"→\", panel[\"month_id\"].max())\n",
    "print(\"Counts by month (tail):\")\n",
    "print(panel[\"month_id\"].value_counts().sort_index().tail(6))\n",
    "\n",
    "missing_cols = [c for c in [\"monthly_volume\",\"avg_volume_3m\",\"volume_ratio\",\"price_range_ratio\",\"trading_days\"]\n",
    "                if c not in stock.columns]\n",
    "if missing_cols:\n",
    "    print(\"Missing in stock_data.csv:\", missing_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kGo_fM5n39gX"
   },
   "source": [
    "MODELO 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 634
    },
    "execution": {
     "iopub.execute_input": "2025-09-08T12:04:35.640761Z",
     "iopub.status.busy": "2025-09-08T12:04:35.640674Z",
     "iopub.status.idle": "2025-09-08T12:04:41.763951Z",
     "shell.execute_reply": "2025-09-08T12:04:41.763435Z"
    },
    "id": "dNVBR4Ho38yO",
    "outputId": "65ffec72-2325-4ff4-cef9-003961233453"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train/X_test shapes: (1069738, 37) (25618, 37)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/valentinaovallevelandia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: divide by zero encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/valentinaovallevelandia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: overflow encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/valentinaovallevelandia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: invalid value encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/valentinaovallevelandia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: divide by zero encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/valentinaovallevelandia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: overflow encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/valentinaovallevelandia/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: invalid value encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/valentinaovallevelandia/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/valentinaovallevelandia/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/valentinaovallevelandia/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Length of values (25618) does not match length of index (616)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 54\u001b[0m\n\u001b[1;32m     51\u001b[0m pred  \u001b[38;5;241m=\u001b[39m (proba \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m     53\u001b[0m preds_lr \u001b[38;5;241m=\u001b[39m test_df[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstock_id\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmonth_id\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\u001b[38;5;241m.\u001b[39mdrop_duplicates()\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m---> 54\u001b[0m \u001b[43mpreds_lr\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mproba\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m proba\n\u001b[1;32m     55\u001b[0m preds_lr[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpred\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m pred\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# If ground truth for July exists, print quick metrics\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/frame.py:4316\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4313\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_array([key], value)\n\u001b[1;32m   4314\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   4315\u001b[0m     \u001b[38;5;66;03m# set column\u001b[39;00m\n\u001b[0;32m-> 4316\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_item\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/frame.py:4529\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4519\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_set_item\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, value) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   4520\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4521\u001b[0m \u001b[38;5;124;03m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[1;32m   4522\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4527\u001b[0m \u001b[38;5;124;03m    ensure homogeneity.\u001b[39;00m\n\u001b[1;32m   4528\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4529\u001b[0m     value, refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sanitize_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4531\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   4532\u001b[0m         key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[1;32m   4533\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   4534\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value\u001b[38;5;241m.\u001b[39mdtype, ExtensionDtype)\n\u001b[1;32m   4535\u001b[0m     ):\n\u001b[1;32m   4536\u001b[0m         \u001b[38;5;66;03m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[1;32m   4537\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mis_unique \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns, MultiIndex):\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/frame.py:5273\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   5270\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _reindex_for_setitem(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\n\u001b[1;32m   5272\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_list_like(value):\n\u001b[0;32m-> 5273\u001b[0m     \u001b[43mcom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequire_length_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5274\u001b[0m arr \u001b[38;5;241m=\u001b[39m sanitize_array(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   5275\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   5276\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(value, Index)\n\u001b[1;32m   5277\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5280\u001b[0m     \u001b[38;5;66;03m# TODO: Remove kludge in sanitize_array for string mode when enforcing\u001b[39;00m\n\u001b[1;32m   5281\u001b[0m     \u001b[38;5;66;03m# this deprecation\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/common.py:573\u001b[0m, in \u001b[0;36mrequire_length_match\u001b[0;34m(data, index)\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    570\u001b[0m \u001b[38;5;124;03mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    572\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(index):\n\u001b[0;32m--> 573\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    574\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength of values \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    575\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    576\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoes not match length of index \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    577\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(index)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    578\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Length of values (25618) does not match length of index (616)"
     ]
    }
   ],
   "source": [
    "# ===== Model A: Logistic Regression (with scaling) =====\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, balanced_accuracy_score, f1_score\n",
    "\n",
    "# preprocessors\n",
    "num_pipe = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "try:\n",
    "    ohe = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
    "except TypeError:  # older sklearn\n",
    "    ohe = OneHotEncoder(handle_unknown=\"ignore\", sparse=False)\n",
    "\n",
    "cat_pipe = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"ohe\", ohe)\n",
    "])\n",
    "\n",
    "pre = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", num_pipe, numeric_cols),\n",
    "        (\"cat\", cat_pipe, categorical_cols),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    "    verbose_feature_names_out=False,\n",
    ")\n",
    "\n",
    "clf = LogisticRegression(\n",
    "    max_iter=2000,\n",
    "    class_weight=\"balanced\",\n",
    "    C=1.0,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "pipe_lr = Pipeline([\n",
    "    (\"pre\", pre),\n",
    "    (\"clf\", clf)\n",
    "])\n",
    "\n",
    "print(\"X_train/X_test shapes:\", X_train.shape, X_test.shape)\n",
    "pipe_lr.fit(X_train, y_train)\n",
    "\n",
    "# July 2023 predictions\n",
    "proba = pipe_lr.predict_proba(X_test)[:, 1]\n",
    "pred  = (proba >= 0.5).astype(int)\n",
    "\n",
    "preds_lr = test_df[[\"stock_id\",\"month_id\"]].drop_duplicates().copy()\n",
    "preds_lr[\"proba\"] = proba\n",
    "preds_lr[\"pred\"] = pred\n",
    "\n",
    "# If ground truth for July exists, print quick metrics\n",
    "y_test_jul = globals().get('y_test_jul', None)\n",
    "if y_test_jul is not None and y_test_jul.notna().any():\n",
    "    y_true = y_test_jul.values.astype(int)\n",
    "    print(\"LR — July 2023\")\n",
    "    print(\"  AUC:                \", round(roc_auc_score(y_true, proba), 4))\n",
    "    print(\"  Accuracy:           \", round(accuracy_score(y_true, pred), 4))\n",
    "    print(\"  Balanced Accuracy:  \", round(balanced_accuracy_score(y_true, pred), 4))\n",
    "    print(\"  F1 (positive=1):    \", round(f1_score(y_true, pred), 4))\n",
    "\n",
    "# Top candidates\n",
    "preds_lr.sort_values(\"proba\", ascending=False).head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JAE1Eew_D_fy"
   },
   "source": [
    "MODEL 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Owt4mkVAEBbU"
   },
   "outputs": [],
   "source": [
    "# ===== Model B: Random Forest (no scaling needed) =====\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, balanced_accuracy_score, f1_score\n",
    "\n",
    "# Preprocessing for trees: impute only + OHE\n",
    "num_pipe = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "])\n",
    "\n",
    "try:\n",
    "    ohe = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
    "except TypeError:\n",
    "    ohe = OneHotEncoder(handle_unknown=\"ignore\", sparse=False)\n",
    "\n",
    "cat_pipe = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"ohe\", ohe)\n",
    "])\n",
    "\n",
    "pre_tree = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", num_pipe, numeric_cols),\n",
    "        (\"cat\", cat_pipe, categorical_cols),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    "    verbose_feature_names_out=False,\n",
    ")\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=600,\n",
    "    max_depth=None,\n",
    "    min_samples_leaf=2,\n",
    "    class_weight=\"balanced_subsample\",\n",
    "    random_state=RANDOM_STATE,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "pipe_rf = Pipeline([\n",
    "    (\"pre\", pre_tree),\n",
    "    (\"clf\", rf)\n",
    "])\n",
    "\n",
    "pipe_rf.fit(X_train, y_train)\n",
    "\n",
    "proba = pipe_rf.predict_proba(X_test)[:, 1]\n",
    "pred  = (proba >= 0.5).astype(int)\n",
    "\n",
    "preds_rf = test_df[[\"stock_id\",\"month_id\"]].drop_duplicates().copy()\n",
    "preds_rf[\"proba\"] = proba\n",
    "preds_rf[\"pred\"] = pred\n",
    "\n",
    "y_test_jul = globals().get('y_test_jul', None)\n",
    "if y_test_jul is not None and y_test_jul.notna().any():\n",
    "    y_true = y_test_jul.values.astype(int)\n",
    "    print(\"RF — July 2023\")\n",
    "    print(\"  AUC:                \", round(roc_auc_score(y_true, proba), 4))\n",
    "    print(\"  Accuracy:           \", round(accuracy_score(y_true, pred), 4))\n",
    "    print(\"  Balanced Accuracy:  \", round(balanced_accuracy_score(y_true, pred), 4))\n",
    "    print(\"  F1 (positive=1):    \", round(f1_score(y_true, pred), 4))\n",
    "\n",
    "preds_rf.sort_values(\"proba\", ascending=False).head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dn4APXfwEdZb"
   },
   "source": [
    "MODELO 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q6__CB_3Ecy4"
   },
   "outputs": [],
   "source": [
    "# ===== Model C: HistGradientBoosting (tree boosting) =====\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.experimental import enable_hist_gradient_boosting  # noqa: F401\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, balanced_accuracy_score, f1_score\n",
    "\n",
    "# Preprocess: impute + dense OHE (HGB needs dense)\n",
    "num_pipe = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "])\n",
    "\n",
    "try:\n",
    "    ohe = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
    "except TypeError:\n",
    "    ohe = OneHotEncoder(handle_unknown=\"ignore\", sparse=False)\n",
    "\n",
    "cat_pipe = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"ohe\", ohe)\n",
    "])\n",
    "\n",
    "pre_hgb = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", num_pipe, numeric_cols),\n",
    "        (\"cat\", cat_pipe, categorical_cols),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    "    verbose_feature_names_out=False,\n",
    ")\n",
    "\n",
    "hgb = HistGradientBoostingClassifier(\n",
    "    learning_rate=0.06,\n",
    "    max_depth=7,            # None also works; 7 is a good start\n",
    "    max_iter=400,\n",
    "    min_samples_leaf=30,\n",
    "    l2_regularization=0.0,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "pipe_hgb = Pipeline([\n",
    "    (\"pre\", pre_hgb),\n",
    "    (\"clf\", hgb)\n",
    "])\n",
    "\n",
    "pipe_hgb.fit(X_train, y_train)\n",
    "\n",
    "proba = pipe_hgb.predict_proba(X_test)[:, 1]\n",
    "pred  = (proba >= 0.5).astype(int)\n",
    "\n",
    "preds_hgb = test_df[[\"stock_id\",\"month_id\"]].drop_duplicates().copy()\n",
    "preds_hgb[\"proba\"] = proba\n",
    "preds_hgb[\"pred\"] = pred\n",
    "\n",
    "y_test_jul = globals().get('y_test_jul', None)\n",
    "if y_test_jul is not None and y_test_jul.notna().any():\n",
    "    y_true = y_test_jul.values.astype(int)\n",
    "    print(\"HGB — July 2023\")\n",
    "    print(\"  AUC:                \", round(roc_auc_score(y_true, proba), 4))\n",
    "    print(\"  Accuracy:           \", round(accuracy_score(y_true, pred), 4))\n",
    "    print(\"  Balanced Accuracy:  \", round(balanced_accuracy_score(y_true, pred), 4))\n",
    "    print(\"  F1 (positive=1):    \", round(f1_score(y_true, pred), 4))\n",
    "\n",
    "preds_hgb.sort_values(\"proba\", ascending=False).head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pm5mdHy7S0VS"
   },
   "outputs": [],
   "source": [
    "def merge_preds(meta, **pred_dfs):\n",
    "    base = meta[[\"stock_id\",\"month_id\"]].drop_duplicates().copy()\n",
    "    for name, dfp in pred_dfs.items():\n",
    "        if dfp is not None:\n",
    "            base = base.merge(\n",
    "                dfp[[\"stock_id\",\"proba\"]].rename(columns={\"proba\": f\"proba_{name}\"}),\n",
    "                on=\"stock_id\", how=\"left\"\n",
    "            )\n",
    "    return base\n",
    "\n",
    "preds_all = merge_preds(\n",
    "    test_df[[\"stock_id\",\"month_id\"]].drop_duplicates(),\n",
    "    lr=preds_lr if \"preds_lr\" in globals() else None,\n",
    "    rf=preds_rf if \"preds_rf\" in globals() else None,\n",
    "    hgb=preds_hgb if \"preds_hgb\" in globals() else None,\n",
    ")\n",
    "\n",
    "proba_cols = [c for c in preds_all.columns if c.startswith(\"proba_\")]\n",
    "preds_all[\"mean_proba\"] = preds_all[proba_cols].mean(axis=1, skipna=True)\n",
    "preds_all[\"vote_1s\"]    = (preds_all[proba_cols] >= 0.5).sum(axis=1)\n",
    "preds_all[\"pred_ens\"]   = (preds_all[\"mean_proba\"] >= 0.5).astype(int)\n",
    "\n",
    "print(\"Rows in July universe:\", len(preds_all))\n",
    "preds_all.sort_values(\"mean_proba\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nMdwSSNnS6Dy"
   },
   "outputs": [],
   "source": [
    "def eval_on_july(name, proba, y_true):\n",
    "    m = ~np.isnan(proba)\n",
    "    y = y_true[m].astype(int)\n",
    "    p = proba[m]\n",
    "    pred = (p >= 0.5).astype(int)\n",
    "    print(f\"{name:>6} | AUC={roc_auc_score(y,p):.3f}  Acc={accuracy_score(y,pred):.3f}  \"\n",
    "          f\"BalAcc={balanced_accuracy_score(y,pred):.3f}  F1={f1_score(y,pred):.3f}  n={m.sum()}\")\n",
    "\n",
    "if y_test_jul is not None and y_test_jul.notna().any():\n",
    "    y_true = y_test_jul.values\n",
    "    for c in proba_cols:\n",
    "        eval_on_july(c.replace(\"proba_\",\"\").upper(), preds_all[c].values, y_true)\n",
    "    eval_on_july(\"ENSEMB\", preds_all[\"mean_proba\"].values, y_true)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FMCDCSVAS_IC"
   },
   "outputs": [],
   "source": [
    "# Ranked picks by ensemble probability\n",
    "ranked = preds_all.sort_values([\"mean_proba\",\"vote_1s\"], ascending=[False, False]).reset_index(drop=True)\n",
    "\n",
    "# Choose a portfolio size (e.g., top 10%); feel free to change\n",
    "k = max(1, int(0.10 * len(ranked)))\n",
    "top_k = ranked.head(k).copy()\n",
    "\n",
    "# Join optional metadata for reporting\n",
    "if \"company\" in globals():\n",
    "    top_k = top_k.merge(company[[\"stock_id\",\"sector\"]], on=\"stock_id\", how=\"left\")\n",
    "\n",
    "print(\"Top-k (k=\", k, \") preview:\")\n",
    "display(top_k.head(15))\n",
    "\n",
    "# If ground truth & excess returns available, grade the portfolio:\n",
    "tj = test_df[\"month_id\"].iloc[0]\n",
    "try:\n",
    "    jul_truth = (test_tgt.loc[test_tgt[\"month_id\"] == tj, [\"stock_id\",\"outperform_binary\",\"excess_return\"]]\n",
    "                         .drop_duplicates(\"stock_id\"))\n",
    "except Exception:\n",
    "    jul_truth = None\n",
    "\n",
    "if jul_truth is not None and not jul_truth.empty:\n",
    "    top_eval = top_k.merge(jul_truth, on=\"stock_id\", how=\"left\")\n",
    "    hit_rate = np.nanmean(top_eval[\"outperform_binary\"])\n",
    "    avg_excess = np.nanmean(top_eval[\"excess_return\"])\n",
    "    print(f\"Top-{k} hit rate: {hit_rate:.3f} | mean excess return: {avg_excess:.3%}\")\n",
    "\n",
    "    # Bottom decile baseline\n",
    "    bot_k = ranked.tail(k).merge(jul_truth, on=\"stock_id\", how=\"left\")\n",
    "    bot_hit = np.nanmean(bot_k[\"outperform_binary\"])\n",
    "    bot_excess = np.nanmean(bot_k[\"excess_return\"])\n",
    "    print(f\"Bottom-{k} hit rate: {bot_hit:.3f} | mean excess return: {bot_excess:.3%}\")\n",
    "    if \"sector\" in top_k.columns:\n",
    "        print(\"\\nTop-k sector mix (% of names):\")\n",
    "        print((top_k[\"sector\"].value_counts(normalize=True)*100).round(1).to_string())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4dQh9gotTCtk"
   },
   "outputs": [],
   "source": [
    "# Random Forest importances\n",
    "try:\n",
    "    rf_feats = list(pipe_rf.named_steps[\"pre\"].get_feature_names_out())\n",
    "    rf_imps  = pipe_rf.named_steps[\"clf\"].feature_importances_\n",
    "    feat_imp_rf = (pd.DataFrame({\"feature\": rf_feats, \"importance\": rf_imps})\n",
    "                    .sort_values(\"importance\", ascending=False)\n",
    "                    .head(25))\n",
    "    display(feat_imp_rf)\n",
    "except Exception as e:\n",
    "    print(\"RF importance not available:\", e)\n",
    "\n",
    "# HistGB importances (if exposed)\n",
    "try:\n",
    "    hgb_feats = list(pipe_hgb.named_steps[\"pre\"].get_feature_names_out())\n",
    "    hgb_imps  = getattr(pipe_hgb.named_steps[\"clf\"], \"feature_importances_\", None)\n",
    "    if hgb_imps is not None:\n",
    "        feat_imp_hgb = (pd.DataFrame({\"feature\": hgb_feats, \"importance\": hgb_imps})\n",
    "                         .sort_values(\"importance\", ascending=False)\n",
    "                         .head(25))\n",
    "        display(feat_imp_hgb)\n",
    "except Exception as e:\n",
    "    print(\"HGB importance not available:\", e)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
